import streamlit as st
import pandas as pd
import nltk
from nltk import tokenize
from bs4 import BeautifulSoup
import requests
from sklearn.metrics.pairwise import cosine_similarity
import io
import docx2txt
from PyPDF2 import PdfReader
import concurrent.futures
from googlesearch import search
import plotly.express as px
from fpdf import FPDF
import xlsxwriter
from functools import lru_cache
import numpy as np
from datetime import datetime
import contextlib

nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')


# H√†m chia vƒÉn b·∫£n th√†nh c√°c c√¢u
def get_sentences(text):
    sentences = tokenize.sent_tokenize(text)
    return sentences

# H√†m t√¨m URL k·∫øt qu·∫£ t√¨m ki·∫øm ƒë·∫ßu ti√™n t·ª´ Google cho m·ªôt c√¢u
def get_url(sentence, timeout=5):
    try:
        base_url = 'https://www.google.com/search?q='
        query = '+'.join(sentence.split())
        url = base_url + query
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        res = requests.get(url, headers=headers, timeout=timeout)
        res.raise_for_status()
        
        soup = BeautifulSoup(res.text, 'html.parser')
        if url := next((a['href'] for div in soup.find_all('div', class_='yuRUbf') 
                       if (a := div.find('a')) and 'youtube' not in a['href']), None):
            return url
        return None
    except Exception:
        return None

# H√†m ƒë·ªçc n·ªôi dung t·ª´ t·ªáp vƒÉn b·∫£n d·∫°ng .txt
def read_text_file(file):
    try:
        file.seek(0)
        return file.read().decode('utf-8')
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file text: {str(e)}")
        return ""

# H√†m ƒë·ªçc n·ªôi dung t·ª´ t·ªáp vƒÉn b·∫£n d·∫°ng .docx
def read_docx_file(file):
    text = docx2txt.process(file)
    return text

# H√†m ƒë·ªçc n·ªôi dung t·ª´ t·ªáp vƒÉn b·∫£n d·∫°ng .pdf
def read_pdf_file(file):
    try:
        text = []
        pdf = PdfReader(file)
        for page in pdf.pages:
            if content := page.extract_text():
                text.append(content)
        return "\n".join(text)
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file PDF: {str(e)}")
        return ""

# H√†m ƒë·ªçc n·ªôi dung t·ª´ t·ªáp vƒÉn b·∫£n (h·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng .txt, .pdf, .docx)
def get_text_from_file(uploaded_file):
    content = ""
    if uploaded_file is not None:
        if uploaded_file.type == "text/plain":
            content = read_text_file(uploaded_file)
        elif uploaded_file.type == "application/pdf":
            content = read_pdf_file(uploaded_file)
        elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            content = read_docx_file(uploaded_file)
    return content

# H√†m l·∫•y n·ªôi dung vƒÉn b·∫£n t·ª´ m·ªôt trang web
def get_text(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        paragraphs = soup.find_all(['p', 'div', 'article'])  # M·ªü r·ªông t√¨m ki·∫øm
        text = ' '.join(p.get_text(strip=True) for p in paragraphs)
        return text
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc n·ªôi dung t·ª´ URL {url}: {str(e)}")
        return ""

# Kh·ªüi t·∫°o m√¥ h√¨nh Ollama
OLLAMA_API = "http://127.0.0.1:11434/v1"
MODEL_NAME = "Tuanpham/t-visstar-7b:latest"

# Cache cho k·∫øt qu·∫£ t√¨m ki·∫øm
@lru_cache(maxsize=100)
def get_google_search_results(query):
    results = list(search(query, num_results=3))
    return results

# H√†m g·ªçi API Ollama
def query_ollama(text1, text2):
    response = requests.post(f"{OLLAMA_API}/generate", json={
        "model": MODEL_NAME,
        "prompt": f"So s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a gi·ªØa hai ƒëo·∫°n vƒÉn b·∫£n sau:\n1. {text1}\n2. {text2}"
    })
    return response.json()['response']

# C·∫≠p nh·∫≠t h√†m get_similarity ƒë·ªÉ ch·ªâ s·ª≠ d·ª•ng Ollama
def get_similarity(text1, text2):
    response = requests.post(f"{OLLAMA_API}/generate", json={
        "model": MODEL_NAME,
        "prompt": f"""So s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai ƒëo·∫°n vƒÉn b·∫£n sau v√† cho ƒëi·ªÉm t·ª´ 0-1:
        VƒÉn b·∫£n 1: {text1}
        VƒÉn b·∫£n 2: {text2}
        
        Tr·∫£ v·ªÅ k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng JSON:
        {{
            "similarity_score": <ƒëi·ªÉm s·ªë t·ª´ 0-1>,
            "analysis": "<ph√¢n t√≠ch chi ti·∫øt>"
        }}
        """
    })
    
    try:
        result = response.json()['response']
        # Parse JSON t·ª´ response string
        import json
        parsed_result = json.loads(result)
        
        similarity_score = float(parsed_result['similarity_score'])
        analysis = parsed_result['analysis']
        
        return similarity_score, analysis
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω response t·ª´ Ollama: {str(e)}")
        return 0.0, "Kh√¥ng th·ªÉ ph√¢n t√≠ch k·∫øt qu·∫£"

# ƒê∆°n gi·∫£n h√≥a h√†m process_pair
def process_pair(i, j, texts=None, filenames=None):
    try:
        text1, text2 = texts[i], texts[j]
        file1, file2 = filenames[i], filenames[j]
        
        similarity_score, analysis = get_similarity(text1, text2)
        
        return {
            'file1': file1,
            'file2': file2,
            'similarity': similarity_score,
            'analysis': analysis
        }
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω c·∫∑p {file1} v√† {file2}: {str(e)}")
        return None

# ƒê∆°n gi·∫£n h√≥a h√†m get_similarity_list
def get_similarity_list(texts, filenames=None):
    if not filenames:
        filenames = [f"T·ªáp {i+1}" for i in range(len(texts))]
    
    pairs = [(i, j) for i in range(len(texts)) for j in range(i+1, len(texts))]
    results = []
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = [
            executor.submit(
                process_pair, 
                i, j, 
                texts=texts,
                filenames=filenames
            ) 
            for i, j in pairs
        ]
        
        for future in concurrent.futures.as_completed(futures):
            if result := future.result():
                results.append(result)
    
    return results

# H√†m t√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa m·ªôt ƒëo·∫°n vƒÉn b·∫£n v√† c√°c vƒÉn b·∫£n l·∫•y t·ª´ danh s√°ch URL
@lru_cache(maxsize=1000)
def get_similarity_cached(text1, text2):
    return get_similarity(text1, text2)

def get_similarity_list2(text, url_list):
    try:
        similarity_list = []
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(
                    lambda u: get_similarity_cached(text, get_text(u)),
                    url
                ) for url in url_list if url
            ]
            
            for future in concurrent.futures.as_completed(futures):
                try:
                    if result := future.result():
                        similarity_list.append(result)
                except Exception as e:
                    st.warning(f"L·ªói khi x·ª≠ l√Ω m·ªôt URL: {str(e)}")
                    continue
                    
        return similarity_list
    except Exception as e:
        st.error(f"L·ªói khi t√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng: {str(e)}")
        return []

# Th√™m h√†m xu·∫•t b√°o c√°o
@contextlib.contextmanager
def st_redirect(src, dst):
    placeholder = st.empty()
    output_func = getattr(placeholder, dst)
    with src as output:
        with contextlib.redirect_stdout(output):
            yield output_func

def export_report(df, format='pdf'):
    try:
        if format == 'pdf':
            pdf = FPDF()
            pdf.add_page()
            # S·ª≠ d·ª•ng font Arial thay v√¨ DejaVu ƒë·ªÉ tr√°nh l·ªói font
            pdf.set_font('Arial', 'B', 16)
            pdf.cell(0, 10, 'Bao cao Kiem tra Dao van', 0, 1, 'C')
            
            pdf.set_font('Arial', '', 12)
            for i, row in df.iterrows():
                for col in df.columns:
                    content = str(row[col])
                    pdf.multi_cell(0, 10, f"{col}: {content}")
                pdf.ln(5)
                
            output_path = f'report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pdf'
            pdf.output(output_path)
            return output_path
            
        else:
            output_path = f'report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'
            with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
                df.to_excel(writer, sheet_name='Ket qua', index=False)
                
                workbook = writer.book
                worksheet = writer.sheets['Ket qua']
                
                header_format = workbook.add_format({
                    'bold': True,
                    'align': 'center',
                    'valign': 'vcenter',
                    'bg_color': '#D9EAD3'
                })
                
                for idx, col in enumerate(df.columns):
                    max_length = max(
                        df[col].astype(str).apply(len).max(),
                        len(col)
                    )
                    worksheet.set_column(idx, idx, max_length + 2)
                    worksheet.write(0, idx, col, header_format)
                    
            return output_path
            
    except Exception as e:
        st.error(f"L·ªói khi xu·∫•t b√°o c√°o: {str(e)}")
        return None

# C·∫≠p nh·∫≠t ph·∫ßn giao di·ªán Streamlit
st.set_page_config(
    page_title='Ph√°t hi·ªán ƒê·∫°o vƒÉn',
    page_icon='üìö',
    layout='wide',  # S·ª≠ d·ª•ng to√†n b·ªô chi·ªÅu r·ªông m√†n h√¨nh
    initial_sidebar_state='expanded',
    menu_items={
        'Get Help': 'https://github.com/yourusername/plagiarism-checker',
        'Report a bug': "https://github.com/yourusername/plagiarism-checker/issues",
        'About': "# ·ª®ng d·ª•ng Ki·ªÉm tra ƒê·∫°o vƒÉn\nPh√°t tri·ªÉn b·ªüi Tho Le"
    }
)

# C·∫≠p nh·∫≠t CSS v·ªõi theme t·ªëi
st.markdown("""
    <style>
    /* Theme t·ªëi */
    [data-testid="stAppViewContainer"] {
        background-color: #1E1E1E;
        color: #FFFFFF;
    }
    
    .stTextArea textarea {
        background-color: #2D2D2D !important;
        color: #FFFFFF !important;
        border: 1px solid #404040 !important;
        font-size: 16px !important;
    }
    
    .stAlert {
        background-color: #2D2D2D !important;
        color: #FFFFFF !important;
        border: 1px solid #404040 !important;
    }
    
    .sidebar .sidebar-content {
        background-color: #2D2D2D;
    }
    
    [data-testid="stMetricValue"] {
        color: #FFFFFF;
    }
    
    /* N√∫t v·ªõi hi·ªáu ·ª©ng hover */
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 4px;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        background-color: #45a049;
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    /* File uploader */
    .stFileUploader {
        background-color: #2D2D2D !important;
        border: 1px dashed #404040 !important;
        padding: 1rem;
    }
    
    /* Tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #2D2D2D;
    }
    
    .stTabs [data-baseweb="tab"] {
        padding: 8px 16px;
        border-radius: 4px;
    }
    
    .stTabs [data-baseweb="tab-highlight"] {
        background-color: #4CAF50;
    }
    
    /* Dataframe */
    [data-testid="stDataFrame"] {
        background-color: #2D2D2D;
    }
    
    /* Progress bar */
    .stProgress > div > div > div > div {
        background-color: #4CAF50;
    }
    
    /* Expander */
    .streamlit-expanderHeader {
        background-color: #2D2D2D !important;
        color: #FFFFFF !important;
    }
    
    /* Metric containers */
    [data-testid="metric-container"] {
        background-color: #2D2D2D;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #404040;
    }
    
    /* Scrollbar */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }
    
    ::-webkit-scrollbar-track {
        background: #2D2D2D;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #404040;
        border-radius: 5px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #4CAF50;
    }
    </style>
    """, unsafe_allow_html=True)

# Header v·ªõi logo v√† ti√™u ƒë·ªÅ
col1, col2, col3 = st.columns([1,2,1])
with col2:
    st.title('üîç Web Ki·ªÉm Tra ƒê·∫°o VƒÉn')

# Sidebar v·ªõi c√°c t√πy ch·ªçn
with st.sidebar:
    st.title("‚öôÔ∏è T√πy ch·ªçn")
    
    with st.expander("C√†i ƒë·∫∑t b√°o c√°o", expanded=True):
        export_format = st.selectbox(
            "üìÑ ƒê·ªãnh d·∫°ng xu·∫•t b√°o c√°o",
            ['PDF', 'Excel'],
            help="Ch·ªçn ƒë·ªãnh d·∫°ng file ƒë·ªÉ xu·∫•t b√°o c√°o"
        )
        
        if st.button('üì• Xu·∫•t b√°o c√°o'):
            if st.session_state.df is not None:
                with st.spinner('ƒêang t·∫°o b√°o c√°o...'):
                    try:
                        output_path = export_report(st.session_state.df, format=export_format.lower())
                        if output_path:
                            with open(output_path, 'rb') as f:
                                mime_type = 'application/pdf' if export_format.lower() == 'pdf' else 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                                st.download_button(
                                    f'‚¨áÔ∏è T·∫£i xu·ªëng b√°o c√°o {export_format}',
                                    f,
                                    file_name=output_path,
                                    mime=mime_type
                                )
                    except Exception as e:
                        st.error(f"L·ªói khi t·∫°o b√°o c√°o: {str(e)}")
            else:
                st.warning("Vui l√≤ng ki·ªÉm tra ƒë·∫°o vƒÉn tr∆∞·ªõc khi xu·∫•t b√°o c√°o")

# Main content
st.markdown("### üìù Nh·∫≠p vƒÉn b·∫£n ho·∫∑c t·∫£i l√™n t·ªáp ƒë·ªÉ ki·ªÉm tra ƒë·∫°o vƒÉn")

# Tabs thay v√¨ radio buttons
tab1, tab2, tab3 = st.tabs(["‚úèÔ∏è Nh·∫≠p vƒÉn b·∫£n", "üìÅ Ki·ªÉm tra t·ªáp vƒÉn b·∫£n", "üîÑ So s√°nh t·ªáp vƒÉn b·∫£n"])

# Th√™m bi·∫øn state ƒë·ªÉ l∆∞u tr·ªØ DataFrame
if 'df' not in st.session_state:
    st.session_state.df = None

# X·ª≠ l√Ω ch·ª©c nƒÉng cho t·ª´ng tab
with tab1:
    # T·∫°o form ƒë·ªÉ b·∫Øt s·ª± ki·ªán Enter
    with st.form(key='text_input_form', clear_on_submit=False):
        text = st.text_area(
            "Nh·∫≠p vƒÉn b·∫£n v√†o ƒë√¢y",
            height=200,
            placeholder="Nh·∫≠p vƒÉn b·∫£n c·∫ßn ki·ªÉm tra v√† nh·∫•n Ctrl+Enter ho·∫∑c n√∫t Ki·ªÉm tra ƒë·∫°o vƒÉn",
            help="Nh·∫•n Ctrl+Enter ho·∫∑c n√∫t Ki·ªÉm tra ƒë·∫°o vƒÉn ƒë·ªÉ b·∫Øt ƒë·∫ßu ki·ªÉm tra",
            key='text_input'
        )
        
        col1, col2, col3 = st.columns([1,2,1])
        with col2:
            submit_button = st.form_submit_button(
                label='üîç Ki·ªÉm tra ƒë·∫°o vƒÉn',
                use_container_width=True,
                type='primary'  # L√†m n·ªïi b·∫≠t n√∫t
            )
        
    if submit_button:
        if not text:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c·∫ßn ki·ªÉm tra")
            st.stop()
            
        with st.spinner('üîÑ ƒêang ph√¢n t√≠ch vƒÉn b·∫£n...'):
            sentences = get_sentences(text)
            urls = []
            similarity_scores = []
            analyses = []
            
            # X·ª≠ l√Ω t·ª´ng c√¢u
            progress_bar = st.progress(0)
            for idx, sentence in enumerate(sentences):
                # T√¨m URL
                url = get_url(sentence)
                urls.append(url)
                
                if url:
                    # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
                    similarity_score, analysis = get_similarity(sentence, get_text(url))
                    similarity_scores.append(similarity_score)
                    analyses.append(analysis)
                else:
                    similarity_scores.append(0)
                    analyses.append("Kh√¥ng t√¨m th·∫•y ngu·ªìn t∆∞∆°ng ƒë·ªìng")
                
                progress_bar.progress((idx + 1) / len(sentences))
            
            # T·∫°o DataFrame k·∫øt qu·∫£
            st.session_state.df = pd.DataFrame({
                'C√¢u': sentences,
                'URL': urls,
                'T·ª∑ l·ªá': [f"{score*100:.2f}%" for score in similarity_scores],
                'Ph√¢n t√≠ch': analyses
            })
            st.session_state.df_type = 'text'

with tab2:
    uploaded_file = st.file_uploader(
        "T·∫£i l√™n t·ªáp (.docx, .pdf, .txt)",
        type=["docx", "pdf", "txt"],
        help="H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng: DOCX, PDF, TXT"
    )
    
    if uploaded_file:
        with st.expander("üëÅÔ∏è Xem tr∆∞·ªõc n·ªôi dung", expanded=False):
            preview_text = get_text_from_file(uploaded_file)
            st.text_area("N·ªôi dung t·ªáp:", value=preview_text, height=150)
        
        col1, col2, col3 = st.columns([1,2,1])
        with col2:
            check_button = st.button(
                'üîç Ki·ªÉm tra ƒë·∫°o vƒÉn',
                key='check2',
                use_container_width=True
            )
        
        if check_button:
            with st.spinner('üîÑ ƒêang ph√¢n t√≠ch t·ªáp...'):
                text = get_text_from_file(uploaded_file)
                sentences = get_sentences(text)
                
                urls = []
                similarity_scores = []
                analyses = []
                
                progress_bar = st.progress(0)
                for idx, sentence in enumerate(sentences):
                    url = get_url(sentence)
                    urls.append(url)
                    
                    if url:
                        similarity_score, analysis = get_similarity(sentence, get_text(url))
                        similarity_scores.append(similarity_score)
                        analyses.append(analysis)
                    else:
                        similarity_scores.append(0)
                        analyses.append("Kh√¥ng t√¨m th·∫•y ngu·ªìn t∆∞∆°ng ƒë·ªìng")
                    
                    progress_bar.progress((idx + 1) / len(sentences))
                
                st.session_state.df = pd.DataFrame({
                    'C√¢u': sentences,
                    'URL': urls,
                    'T·ª∑ l·ªá': [f"{score*100:.2f}%" for score in similarity_scores],
                    'Ph√¢n t√≠ch': analyses
                })
                st.session_state.df_type = 'file'

with tab3:
    col1, col2 = st.columns([2,1])
    with col1:
        uploaded_files = st.file_uploader(
            "T·∫£i l√™n nhi·ªÅu t·ªáp (.docx, .pdf, .txt)",
            type=["docx", "pdf", "txt"],
            accept_multiple_files=True,
            help="C√≥ th·ªÉ ch·ªçn nhi·ªÅu t·ªáp c√πng l√∫c"
        )
    with col2:
        similarity_threshold = st.slider(
            "üéØ Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng (%)",
            min_value=0,
            max_value=100,
            value=50,
            help="Ch·ªâ hi·ªÉn th·ªã k·∫øt qu·∫£ c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng l·ªõn h∆°n ng∆∞·ª°ng n√†y"
        )
    
    if uploaded_files and len(uploaded_files) >= 2:
        col1, col2, col3 = st.columns([1,2,1])
        with col2:
            compare_button = st.button(
                'üîç So s√°nh c√°c t·ªáp',
                key='check3',
                use_container_width=True
            )
        
        if compare_button:
            with st.spinner('üîÑ ƒêang so s√°nh c√°c t·ªáp...'):
                texts = []
                filenames = []
                
                # ƒê·ªçc n·ªôi dung c√°c t·ªáp
                for file in uploaded_files:
                    text = get_text_from_file(file)
                    texts.append(text)
                    filenames.append(file.name)
                
                # So s√°nh c√°c t·ªáp
                results = get_similarity_list(texts, filenames)
                
                # L·ªçc k·∫øt qu·∫£ theo ng∆∞·ª°ng
                filtered_results = [
                    r for r in results 
                    if float(r['similarity']) * 100 >= similarity_threshold
                ]
                
                if filtered_results:
                    st.session_state.df = pd.DataFrame(filtered_results)
                    st.session_state.df['T·ª∑ l·ªá'] = st.session_state.df['similarity'].apply(
                        lambda x: f"{float(x)*100:.2f}%"
                    )
                    st.session_state.df = st.session_state.df.drop('similarity', axis=1)
                    st.session_state.df_type = 'comparison'
                else:
                    st.warning("‚ùó Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o v∆∞·ª£t ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng")
    else:
        st.info("‚ÑπÔ∏è Vui l√≤ng t·∫£i l√™n √≠t nh·∫•t 2 t·ªáp ƒë·ªÉ so s√°nh")

# C·∫£i thi·ªán h√†m v·∫Ω bi·ªÉu ƒë·ªì
def create_similarity_chart(df_plot, chart_type='bar'):
    if chart_type == 'bar':
        fig = px.bar(
            df_plot,
            x=df_plot.index,
            y='T·ª∑ l·ªá',
            title='Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng',
            labels={'index': 'STT', 'T·ª∑ l·ªá': 'ƒê·ªô t∆∞∆°ng ƒë·ªìng (%)'},
            template='plotly_dark'
        )
    else:  # chart_type == 'scatter'
        fig = px.scatter(
            df_plot,
            x=df_plot.index,
            y='T·ª∑ l·ªá',
            title='Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng',
            labels={'index': 'STT', 'T·ª∑ l·ªá': 'ƒê·ªô t∆∞∆°ng ƒë·ªìng (%)'},
            template='plotly_dark'
        )

    # C·∫£i thi·ªán giao di·ªán bi·ªÉu ƒë·ªì
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0.1)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', size=14),
        margin=dict(l=40, r=40, t=60, b=40),
        showlegend=True,
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="right",
            x=0.99,
            bgcolor='rgba(0,0,0,0.5)'
        ),
        hovermode='x unified'
    )

    # Th√™m ƒë∆∞·ªùng ng∆∞·ª°ng tham chi·∫øu
    fig.add_hline(
        y=50,  # Ng∆∞·ª°ng 50%
        line_dash="dash",
        line_color="red",
        annotation_text="Ng∆∞·ª°ng c·∫£nh b√°o (50%)",
        annotation_position="bottom right"
    )

    fig.update_traces(
        marker_color='#4CAF50',
        marker_line_color='#45a049',
        marker_line_width=1.5,
        opacity=0.8,
        hovertemplate='<b>STT</b>: %{x}<br>' +
                      '<b>ƒê·ªô t∆∞∆°ng ƒë·ªìng</b>: %{y:.1f}%<extra></extra>'
    )

    return fig

# C·∫£i thi·ªán hi·ªÉn th·ªã k·∫øt qu·∫£
if st.session_state.df is not None:
    with st.container():
        st.markdown("### üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
        
        # Th√™m tabs cho ph√¢n t√≠ch
        analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs([
            "üìà T·ªïng quan", 
            "üìä Bi·ªÉu ƒë·ªì ph√¢n t√≠ch",
            "üìã Chi ti·∫øt"
        ])
        
        with analysis_tab1:
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.session_state.df_type in ['text', 'file']:
                    total_sentences = len(st.session_state.df)
                    st.metric(
                        "üìù T·ªïng s·ªë c√¢u/ƒëo·∫°n", 
                        f"{total_sentences:,}",
                        delta=None
                    )
                else:
                    st.metric("üìë S·ªë c·∫∑p so s√°nh", len(st.session_state.df))
            
            with col2:
                avg_similarity = st.session_state.df['T·ª∑ l·ªá'].str.rstrip('%').astype(float).mean()
                st.metric(
                    "üìä ƒê·ªô t∆∞∆°ng ƒë·ªìng trung b√¨nh", 
                    f"{avg_similarity:.1f}%",
                    delta=f"{avg_similarity-50:.1f}%" if avg_similarity > 50 else None,
                    delta_color="inverse"
                )
            
            with col3:
                if st.session_state.df_type in ['text', 'file']:
                    unique_sources = len([url for url in st.session_state.df['URL'].unique() if url is not None])
                    st.metric(
                        "üîó Ngu·ªìn ph√°t hi·ªán", 
                        f"{unique_sources:,}",
                        help="S·ªë l∆∞·ª£ng ngu·ªìn ƒë·ªôc l·∫≠p ƒë∆∞·ª£c ph√°t hi·ªán"
                    )
                else:
                    total_files = len(set(st.session_state.df['file1'].unique()) | 
                                    set(st.session_state.df['file2'].unique()))
                    st.metric("üìö T·ªáp ƒë√£ so s√°nh", f"{total_files:,}")

        with analysis_tab2:
            # Th√™m t√πy ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì
            chart_type = st.radio(
                "Ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì:",
                ['Bar Chart', 'Scatter Plot'],
                horizontal=True
            )
            
            df_plot = st.session_state.df.copy()
            df_plot['T·ª∑ l·ªá'] = df_plot['T·ª∑ l·ªá'].str.rstrip('%').astype(float)
            
            fig = create_similarity_chart(
                df_plot, 
                'bar' if chart_type == 'Bar Chart' else 'scatter'
            )
            st.plotly_chart(fig, use_container_width=True, theme=None)

        with analysis_tab3:
            # Th√™m b·ªô l·ªçc v√† s·∫Øp x·∫øp
            col1, col2 = st.columns([2,1])
            with col1:
                search_term = st.text_input(
                    "üîç T√¨m ki·∫øm",
                    placeholder="Nh·∫≠p t·ª´ kh√≥a ƒë·ªÉ l·ªçc..."
                )
            with col2:
                sort_by = st.selectbox(
                    "S·∫Øp x·∫øp theo",
                    ['T·ª∑ l·ªá gi·∫£m d·∫ßn', 'T·ª∑ l·ªá tƒÉng d·∫ßn']
                )
            
            # L·ªçc v√† s·∫Øp x·∫øp DataFrame
            filtered_df = st.session_state.df.copy()
            if search_term:
                mask = filtered_df.astype(str).apply(
                    lambda x: x.str.contains(search_term, case=False)
                ).any(axis=1)
                filtered_df = filtered_df[mask]
            
            # S·∫Øp x·∫øp
            filtered_df['sort_value'] = filtered_df['T·ª∑ l·ªá'].str.rstrip('%').astype(float)
            filtered_df = filtered_df.sort_values(
                'sort_value',
                ascending=sort_by == 'T·ª∑ l·ªá tƒÉng d·∫ßn'
            ).drop('sort_value', axis=1)
            
            st.dataframe(
                filtered_df,
                use_container_width=True,
                column_config={
                    'URL': st.column_config.LinkColumn('URL'),
                    'T·ª∑ l·ªá': st.column_config.ProgressColumn(
                        'ƒê·ªô t∆∞∆°ng ƒë·ªìng',
                        format='%s',
                        min_value='0%',
                        max_value='100%',
                        help="ƒê·ªô t∆∞∆°ng ƒë·ªìng v·ªõi ngu·ªìn ƒë∆∞·ª£c ph√°t hi·ªán"
                    )
                }
            )

# C·∫≠p nh·∫≠t footer v·ªõi theme t·ªëi
st.markdown("""
    <div style='text-align: center; color: #808080; padding: 20px;'>
        <hr style='border-color: #404040;'>
        <p>¬© 2024 Web Ki·ªÉm Tra ƒê·∫°o VƒÉn | Ph√°t tri·ªÉn b·ªüi Tho Le</p>
    </div>
""", unsafe_allow_html=True)

def auto_export_report(df, format='pdf'):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"report_{timestamp}.{format}"
    
    if format == 'pdf':
        export_report(df, 'pdf')
        with open(filename, "rb") as f:
            st.download_button(
                "T·∫£i xu·ªëng b√°o c√°o PDF",
                f,
                filename,
                "application/pdf"
            )
    else:
        export_report(df, 'xlsx')
        with open(filename, "rb") as f:
            st.download_button(
                "T·∫£i xu·ªëng b√°o c√°o Excel",
                f,
                filename,
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
